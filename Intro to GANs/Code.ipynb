{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks \n",
    "\n",
    "## Training a GAN on the Generative Dog Images dataset from the corresponding Kaggle Competition.\n",
    "\n",
    "### Note: Can receive a OOM error when training the GAn if there is insufficient VRAM available.\n",
    "\n",
    "### Dataset contains images and their respective bounding boxes in annotation files.\n",
    "\n",
    "### Train the discriminator to reduce the error when trying to recognise the difference between generated images (Some of which are Fake) and the real images as much as possible. To train the discriminator, noise is introduced into the generator\n",
    "### in the form of fake images meant to fool the discriminator network. The approach is game theoretic which means that if either the discriminator or the generator improves during the training session, (that is, the generator becomes more adept\n",
    "### at fooling the discriminator by introducing more complex noise or the discriminator becomes more adept at recognising the difference between real and fake images) the other has to up the ante in order to be competent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout,Concatenate\n",
    "from keras.backend import random_normal,ones_like,zeros_like,mean\n",
    "from keras.backend import get_session\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import concatenate\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping, History\n",
    "from PIL import Image\n",
    "import warnings\n",
    "import os\n",
    "import time\n",
    "from glob import glob\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np, pandas as pd, os\n",
    "import xml.etree.ElementTree as ET \n",
    "import matplotlib.pyplot as plt, zipfile \n",
    "from PIL import Image \n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data and Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMS = os.listdir('Data/all-dogs/')\n",
    "breeds = os.listdir('Data/Annotation/')\n",
    "\n",
    "idxArray = 0; namesArray = []\n",
    "imagesArray = np.zeros((25000,64,64,3))\n",
    "\n",
    "print(breeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the corresponding bounding boxes for each breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOGS = False\n",
    "if DOGS:\n",
    "    for breed in breeds:\n",
    "        for dog in os.listdir('Data/Annotation/'+ breed):\n",
    "            try: img = Image.open('all-dogs/'+ dog + '.jpg')\n",
    "            except: continue\n",
    "\n",
    "            tree = ET.parse('Data/Annotation/'+ breed + '/'+ dog)\n",
    "            root = tree.getroot()\n",
    "            objects = root.findall('object')\n",
    "\n",
    "            for o in objects:\n",
    "                boundbox = o.find('bndbox')\n",
    "                xmin = int(boundbox.find('xmin').text)\n",
    "                xmax = int(boundbox.find('xmax').text)\n",
    "                ymin = int(boundbox.find('ymin').text)\n",
    "                ymax = int(boundbox.find('ymax').text)\n",
    "\n",
    "                w = np.min((xmax-xmin, ymax-ymin))\n",
    "                im2 = img.crop((xmin, ymin, xmin+w, ymin+w))\n",
    "                im2 = im2.resize((64,64), Image.ANTIALIAS)\n",
    "\n",
    "                imagesArray[idxArray,:,:,:] = np.asarray(im2)\n",
    "\n",
    "                namesArray.append(breed)\n",
    "                idxArray+=1\n",
    "\n",
    "else:\n",
    "    IMAGES = np.sort(IMS)\n",
    "    np.random.seed(810)\n",
    "    x = np.random.choice(np.arange(20579),10000)\n",
    "    np.random.seed(None)\n",
    "    for k in range(len(x)):\n",
    "        img = Image.open('Data/all-dogs/' + IMAGES[x[k]])\n",
    "        w = img.size[0]; h = img.size[1]\n",
    "        if (k%2==0)|(k%3==0):\n",
    "            w2 = 100; h2 = int(h/(w/100))\n",
    "            a = 18; b = 0          \n",
    "        else:\n",
    "            a=0; b=0\n",
    "            if w<h:\n",
    "                w2 = 64; h2 = int((64/w)*h)\n",
    "                b = (h2-64)//2\n",
    "            else:\n",
    "                h2 = 64; w2 = int((64/h)*w)\n",
    "                a = (w2-64)//2\n",
    "        img = img.resize((w2,h2), Image.ANTIALIAS)\n",
    "        img = img.crop((0+a, 0+b, 64+a, 64+b))    \n",
    "        imagesArray[idxArray,:,:,:] = np.asarray(img)\n",
    "        namesArray.append(IMAGES[x[k]])\n",
    "        idxArray += 1\n",
    "x = np.random.randint(0, idxArray, 25)\n",
    "for k in range(5):\n",
    "    plt.figure(figsize=(15,3))\n",
    "    for j in range(5):\n",
    "        plt.subplot(1, 5, j+1)\n",
    "        img = Image.fromarray(imagesArray[x[k*5+j], :, :, :].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = Input((12288,))\n",
    "IMG_SIZE_2 = Input((10000,))\n",
    "NOISE = 10000\n",
    "\n",
    "BATCH = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminatorFn():\n",
    "    input_layer=Dense(12288, activation='sigmoid')(IMG_SIZE_2)\n",
    "    input_layer=Reshape((2,12288,1))(concatenate([IMG_SIZE, input_layer]))\n",
    "    discriminator=Conv2D(filters=1, kernel_size=[2,1], use_bias=False, name = 'layer_1')(input_layer)\n",
    "    out = Flatten()(discriminator)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = discriminatorFn()\n",
    "model_dis = Model([IMG_SIZE,IMG_SIZE_2], model)\n",
    "model_dis.get_layer('layer_1').trainable = False\n",
    "model_dis.get_layer('layer_1').set_weights([np.array([[[[-1.0 ]]],[[[1.0]]]])])\n",
    "model_dis.summary()\n",
    "model_dis.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = (imagesArray[:10000, :, :, :]/255.).reshape((-1,12288))\n",
    "x_train = np.zeros((10000,10000))\n",
    "for i in range(10000): \n",
    "    x_train[i,1] = 1\n",
    "zeros = np.zeros((10000, 12288))\n",
    "\n",
    "lrate = 0.5\n",
    "\n",
    "for k in range(5):\n",
    "    LR_S = LearningRateScheduler(lambda x: lrate)\n",
    "    h = model_dis.fit([zeros, x_train], y_train, epochs = 100, batch_size = BATCH, callbacks = [LR_S], verbose = 0)\n",
    "    if h.history['loss'][-1] < 0.533: lrate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample predictions from the discriminator after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(5):\n",
    "    for j in range(5):\n",
    "        base = np.zeros((10000))\n",
    "        base[np.random.randint(10000)] = 1\n",
    "        img = model_dis.predict([zeros[0,:].reshape((-1,12288)), base.reshape((-1,10000))]).reshape((-1,64,64,3))\n",
    "        img = Image.fromarray( (255*img).astype('uint8').reshape((64,64,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_gen(noise_shape=(NOISE,)):\n",
    "    in_layer = Input(noise_shape)\n",
    "    gen = Dense(12288, activation='linear')(in_layer)\n",
    "\n",
    "    model = Model(inputs=in_layer, outputs = [gen, Reshape((10000, ))(in_layer)])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_generator = model_gen(noise_shape=(NOISE,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dis.trainable = False\n",
    "ins = Input(shape = (NOISE,))\n",
    "img = model_generator(ins)\n",
    "real = model_dis(img)\n",
    "\n",
    "gan = Model(ins, real)\n",
    "gan.get_layer('model').get_layer('layer_1').set_weights([np.array([[[[-1]]], [[[255,]]]])])\n",
    "gan.compile(optimizer=Adam(5), loss = 'mean_squared_error')\n",
    "\n",
    "\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.zeros((10000,10000))\n",
    "for i in range(10000): train[i,i]=1\n",
    "zeros = np.zeros((10000, 12288))\n",
    "\n",
    "steps = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "lr = 5.\n",
    "\n",
    "for step in range(steps):\n",
    "\n",
    "    LR_S = LearningRateScheduler(lambda x: lr)\n",
    "    h = gan.fit(train, zeros, epochs = 1, batch_size=256, callbacks=[LR_S], verbose=0)\n",
    "\n",
    "    if (step<10)|(step%5==4):\n",
    "        print (\"Step: {}/{} [G loss: {:.4f}]\".format(\n",
    "                     (step+1)*10, steps*10, h.history['loss'][-1]))\n",
    "    \n",
    "    if h.history['loss'][-1] < 25: lr = 1. \n",
    "    if h.history['loss'][-1] < 1.5: lr = 0.01\n",
    "\n",
    "    if step<10:\n",
    "        plt.figure(figsize=(15,3))\n",
    "        for j in range(5):\n",
    "            zz = np.zeros((10000))\n",
    "            zz[np.random.randint(10000)] = 1\n",
    "            plt.subplot(1,5,j+1)\n",
    "            img = model_generator.predict(zz.reshape((-1,10000)))[0].reshape((-1,64,64,3))\n",
    "            img = Image.fromarray( (img).astype('uint8').reshape((64,64,3)))\n",
    "            plt.axis('off')\n",
    "            plt.imshow(img)\n",
    "        plt.show()    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
