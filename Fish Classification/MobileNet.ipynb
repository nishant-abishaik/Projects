{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Importing relevant libraries\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from pathlib import Path\r\n",
    "import os.path\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from IPython.display import Image, display\r\n",
    "import matplotlib.cm as cm\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import tensorflow as tf\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Set the image directory using Path and isolate labels and image names using path.split through the anonymous function method.\r\n",
    "\r\n",
    "image_dir = Path('Data\\Fish_Dataset\\Fish_Dataset')\r\n",
    "\r\n",
    "filespaths = list(image_dir.glob(r'**/*.png'))\r\n",
    "labelspaths = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filespaths))\r\n",
    "\r\n",
    "filespaths = pd.Series(filespaths, name='Filepath').astype(str)\r\n",
    "labels = pd.Series(labelspaths, name='Label')\r\n",
    "\r\n",
    "#Create the image dataframe with the image paths and labels as the columns. \r\n",
    "\r\n",
    "image_frame = pd.concat([filespaths, labels], axis=1)\r\n",
    "\r\n",
    "#Removing the GT Images\r\n",
    "\r\n",
    "image_frame = image_frame[image_frame['Label'].apply(lambda x: x[-2:] != 'GT')]\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Shuffle the dataframe by sampling it.\r\n",
    "\r\n",
    "image_frame = image_frame.sample(frac=1).reset_index(drop= True)\r\n",
    "\r\n",
    "image_frame.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#SPlitting the dataset into the training and test dataframes with a 10% test size.\r\n",
    "\r\n",
    "df_train, df_test = train_test_split(image_frame, train_size=0.9, shuffle= True, random_state=1)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Initialize the generators and set the validation size to 20% of the training set. The validation dataframe allows for overfitting monitoring through the validation loss.\r\n",
    "\r\n",
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\r\n",
    "    preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input, validation_split = 0.2\r\n",
    ")\r\n",
    "\r\n",
    "test_gen = tf.keras.preprocessing.image.ImageDataGenerator(\r\n",
    "    preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_im = train_gen.flow_from_dataframe(\r\n",
    "    dataframe = df_train, \r\n",
    "    x_col = 'Filepath', \r\n",
    "    y_col = 'Label', \r\n",
    "    target_size = (224, 244),\r\n",
    "    color_mode = 'rgb', \r\n",
    "    class_mode = 'categorical', \r\n",
    "    batch_size = 32, \r\n",
    "    shuffle = True, \r\n",
    "    seed = 50, \r\n",
    "    subset = 'training'\r\n",
    ")\r\n",
    "\r\n",
    "val_im = train_gen.flow_from_dataframe(\r\n",
    "    dataframe=df_train,\r\n",
    "    x_col='Filepath',\r\n",
    "    y_col='Label',\r\n",
    "    target_size=(224, 224),\r\n",
    "    color_mode='rgb',\r\n",
    "    class_mode='categorical',\r\n",
    "    batch_size=32,\r\n",
    "    shuffle=True,\r\n",
    "    seed=50,\r\n",
    "    subset='validation'\r\n",
    ")\r\n",
    "\r\n",
    "test_im = test_gen.flow_from_dataframe(\r\n",
    "    dataframe=df_test,\r\n",
    "    x_col='Filepath',\r\n",
    "    y_col='Label',\r\n",
    "    target_size=(224, 224),\r\n",
    "    color_mode='rgb',\r\n",
    "    class_mode='categorical',\r\n",
    "    batch_size=32,\r\n",
    "    shuffle=False\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Load the Imagenet pretrained MobileNetV2 architecture without the output layer and an average pooling.\r\n",
    "pre_mod = tf.keras.applications.MobileNetV2(\r\n",
    "    input_shape = (224, 224, 3),\r\n",
    "    include_top = False, \r\n",
    "    weights = 'imagenet', \r\n",
    "    pooling = 'avg'\r\n",
    ")\r\n",
    "#Freeze the lower layers in order for the model to perform as a stand-alone feature extractor and predictor\r\n",
    "pre_mod.trainable = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "inputs = pre_mod.input\r\n",
    "\r\n",
    "#Replacing the FC layers of the MobileNetV2 with 2 128 FC Layers.\r\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(pre_mod.output)\r\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\r\n",
    "\r\n",
    "outputs = tf.keras.layers.Dense(9, activation='softmax')(x)\r\n",
    "\r\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\r\n",
    "\r\n",
    "model.compile(\r\n",
    "    optimizer = 'adam',\r\n",
    "    loss = 'categorical_crossentropy', \r\n",
    "    metrics = ['accuracy']\r\n",
    ")\r\n",
    "\r\n",
    "#In order to monitor overfit, set earlystopping rounds with a patience of 1 so that there is a limit of one instance of validation loss increasing per epoch.\r\n",
    "history = model.fit(\r\n",
    "    train_im, \r\n",
    "    validation_data = val_im, \r\n",
    "    epochs = 50, \r\n",
    "    callbacks = [ \r\n",
    "        tf.keras.callbacks.EarlyStopping(\r\n",
    "            monitor = 'val_loss',\r\n",
    "            patience=1,\r\n",
    "            restore_best_weights = True\r\n",
    "        )\r\n",
    "    ]\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(history.history)[['loss', 'val_loss']].plot()\r\n",
    "plt.title('Loss')\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(history.history)[['loss','val_loss']].plot()\r\n",
    "plt.title(\"Loss\")\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = model.evaluate(test_im, verbose=0)\r\n",
    "\r\n",
    "print(\"Loss: \", results[0])\r\n",
    "print(\"Accuracy: \", results[1])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}